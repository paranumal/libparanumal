//Analysis:
//Analysis:
// We perform (per thread block)
// Nelements per block x Np x (Npx8+7) flops
// We request: (Nelements per block) x Np x(1+4+Npx4 variables
// We store (Nelements per block) x Np x (1) variables
// flops: 
@kernel void ellipticPartialAxTri2D_v1(const int Nelements,
    @restrict const  int   *  elementList,
    @restrict const  dfloat *  ggeo,
    @restrict const  dfloat *  SrrT,
    @restrict const  dfloat *  SrsT,
    @restrict const  dfloat *  SsrT,
    @restrict const  dfloat *  SssT,
    @restrict const  dfloat *  MM,
    const dfloat lambda,
    @restrict const  dfloat  *  q,
    @restrict dfloat  *  Aq){

  // needs p_NnodesV (nodes per thread) and p_NblockV (elements per chunk) defined

  for(int eo=0;eo<Nelements;eo+=p_NnodesV*p_NblockV;@outer(0)){

    @shared dfloat s_q[p_NnodesV][p_NblockV][p_Np];

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;
            if(e<Nelements){
              //prefetch q
              const int element = elementList[e];
              const int id = n + element*p_Np;
              s_q[et][es][n] = q[id];
            }
          }
      }
    }

    @barrier("local");

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        // do this part irrespective of e
        dfloat r_qrr[p_NnodesV];
        dfloat r_qrs[p_NnodesV];
        dfloat r_qsr[p_NnodesV];
        dfloat r_qss[p_NnodesV];

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            r_qrr[et] = 0;
            r_qrs[et] = 0;
            r_qsr[et] = 0;
            r_qss[et] = 0;
          }

        #pragma unroll p_Np
          for (int k=0;k<p_Np;k++) {
            // prefetch operators to register for reuse
            const int id = n+k*p_Np;
            const dfloat Srr_nk = SrrT[id];
            const dfloat Srs_nk = SrsT[id];
            const dfloat Ssr_nk = SsrT[id];
            const dfloat Sss_nk = SssT[id];

            // (dphidr_n, dphidr_m)*(rx*rx+ry*ry)*q_m
            // (dphidr_n, dphids_m)*(rx*sx+ry*sy)*q_m
            // (dphids_n, dphidr_m)*(sx*rx+sy*ry)*q_m
            // (dphids_n, dphids_m)*(sx*sx+sy*sy)*q_m

            #pragma unroll p_NnodesV{
              for(int et=0;et<p_NnodesV;++et){
                // fetch from @shared (for reuse four times)
                const dfloat r_qk = s_q[et][es][k];

                r_qrr[et] += Srr_nk*r_qk;
                r_qrs[et] += Srs_nk*r_qk; // a. 
                r_qsr[et] += Ssr_nk*r_qk; // b. should probably merge a, b
                // i.e. r_qrs[et] += Shatrs_nk*r_qk
                r_qss[et] += Sss_nk*r_qk;
              }
            }
          }

        // this part has to check for element index validity
        #pragma unroll p_NnodesV{
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;

            if (e<Nelements) {
              const int element = elementList[e];

              const int gid = element*p_Nggeo;

              const dfloat Grr = ggeo[gid + p_G00ID];
              const dfloat Grs = ggeo[gid + p_G01ID];
              const dfloat Gss = ggeo[gid + p_G11ID];
              const dfloat J   = ggeo[gid + p_GWJID];

              dfloat res = Grr*r_qrr[et];
              res += Grs*r_qrs[et]; // A.
              res += Grs*r_qsr[et]; // B. should probably merge these since Grs=Gsr
              res += Gss*r_qss[et];

              const int id = n + element*p_Np;
              Aq[id] = res;
            }
          }
        }
      }
    }
  }
}


@kernel void ellipticPartialAxTri2D_v2(const int Nelements,
    @restrict const  int   *  elementList,
    @restrict const  dfloat *  ggeo,
    @restrict const  dfloat *  SrrT,
    @restrict const  dfloat *  SrsT,
    @restrict const  dfloat *  SsrT,
    @restrict const  dfloat *  SssT,
    @restrict const  dfloat *  MM,
    const dfloat lambda,
    @restrict const  dfloat  *  q,
    @restrict dfloat  *  Aq){

  // needs p_NnodesV (nodes per thread) and p_NblockV (elements per chunk) defined

  for(int eo=0;eo<Nelements;eo+=p_NnodesV*p_NblockV;@outer(0)){

    @shared dfloat s_q[p_NnodesV][p_NblockV][p_Np];

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;
            if(e<Nelements){
              //prefetch q
              const int element = elementList[e];
              const int id = n + element*p_Np;
              s_q[et][es][n] = q[id];
            }
          }
      }
    }

    @barrier("local");

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        // do this part irrespective of e
        dfloat r_qrr[p_NnodesV];
        dfloat r_qrs[p_NnodesV];
        dfloat r_qss[p_NnodesV];

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            r_qrr[et] = 0;
            r_qrs[et] = 0;
            r_qss[et] = 0;
          }

        #pragma unroll p_Np
          for (int k=0;k<p_Np;k++) {
            // prefetch operators to register for reuse
            const int id = n+k*p_Np;
            const dfloat Srr_nk = SrrT[id];
            const dfloat Srs_nk = SrsT[id];
            const dfloat Sss_nk = SssT[id];

            // (dphidr_n, dphidr_m)*(rx*rx+ry*ry)*q_m
            // (dphidr_n, dphids_m)*(rx*sx+ry*sy)*q_m
            // (dphids_n, dphidr_m)*(sx*rx+sy*ry)*q_m
            // (dphids_n, dphids_m)*(sx*sx+sy*sy)*q_m

            #pragma unroll p_NnodesV{
              for(int et=0;et<p_NnodesV;++et){
                // fetch from @shared (for reuse four times)
                const dfloat r_qk = s_q[et][es][k];

                r_qrr[et] += Srr_nk*r_qk;
                r_qrs[et] += Srs_nk*r_qk;
                r_qss[et] += Sss_nk*r_qk;
              }
            }
          }

        // this part has to check for element index validity
        #pragma unroll p_NnodesV{
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;

            if (e<Nelements) {
              const int element = elementList[e];

              const int gid = element*p_Nggeo;

              const dfloat Grr = ggeo[gid + p_G00ID];
              const dfloat Grs = ggeo[gid + p_G01ID];
              const dfloat Gss = ggeo[gid + p_G11ID];
              const dfloat J   = ggeo[gid + p_GWJID];

              dfloat res = Grr*r_qrr[et];
              res += Grs*r_qrs[et]; // A.
              res += Gss*r_qss[et];

              const int id = n + element*p_Np;
              Aq[id] = res;
            }
          }
        }
      }
    }
  }
}
//author: KS

@kernel void ellipticPartialAxTri2D_v3(const int Nelements,
    @restrict const  int   *  elementList,
    @restrict const  dfloat *  ggeo,
    @restrict const  dfloat *  SrrT,
    @restrict const  dfloat *  SrsT,
    @restrict const  int   *  IndT,
    @restrict const  dfloat *  SssT,
    @restrict const  dfloat *  MM,
    const dfloat lambda,
    @restrict const  dfloat  *  q,
    @restrict dfloat  *  Aq){

  // needs p_NnodesV (nodes per thread) and p_NblockV (elements per chunk) defined

  for(int eo=0;eo<Nelements;eo+=p_NnodesV*p_NblockV;@outer(0)){

    @shared dfloat s_q[p_NnodesV][p_NblockV][p_Np];

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;
            if(e<Nelements){
              //prefetch q
              const int element = elementList[e];
              const int id = n + element*p_Np;
              s_q[et][es][n] = q[id];
              //printf("maxNNz = %d \n", p_maxNnzPerRow);           
            }
          }
      }
    }

    @barrier("local");

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        // do this part irrespective of e
        dfloat r_qrr[p_NnodesV];
        dfloat r_qrs[p_NnodesV];
        dfloat r_qss[p_NnodesV];

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            r_qrr[et] = 0;
            r_qrs[et] = 0;
            r_qss[et] = 0;
          }
        //this loop is modified

        #pragma unroll p_maxNnzPerRow
          for (int k=0;k<p_maxNnzPerRow;k++) {
            // prefetch operators to register for reuse

            //if IndList(i,j) ~=0 
            if (IndT[n*p_maxNnzPerRow+k] != 0){
              //result(j) = result(j)+ Srr(j,IndList(i,j))*x(IndList(i,j));
              const int id = IndT[n*p_maxNnzPerRow+k]-1;

              const dfloat Srr_nk = SrrT[id*p_maxNnzPerRow+n];
              const dfloat Srs_nk = SrsT[id*p_maxNnzPerRow+n];
              const dfloat Sss_nk = SssT[id*p_maxNnzPerRow+n];
              /*
                 const dfloat Srr_nk = 1.0;
                 const dfloat Srs_nk = 1.0;
                 const dfloat Sss_nk = 1.0;*/
              /*if (eo+es == 0){
                printf("n = %d, k = %d, requesting Ind[%d] = %d, element Srr[%d] \n",n,k,n*p_maxNnzPerRow+k, IndT[n*p_maxNnzPerRow+k], id*p_maxNnzPerRow+n);
                }*/
              // (dphidr_n, dphidr_m)*(rx*rx+ry*ry)*q_m
              // (dphidr_n, dphids_m)*(rx*sx+ry*sy)*q_m
              // (dphids_n, dphidr_m)*(sx*rx+sy*ry)*q_m
              // (dphids_n, dphids_m)*(sx*sx+sy*sy)*q_m

              #pragma unroll p_NnodesV{
                for(int et=0;et<p_NnodesV;++et){
                  // fetch from @shared (for reuse four times)
                  const dfloat r_qk = s_q[et][es][k];
                  r_qrr[et] += Srr_nk*r_qk;
                  r_qrs[et] += Srs_nk*r_qk;
                  r_qss[et] += Sss_nk*r_qk;
                }
              }
            }
          }
        // this part has to check for element index validity
        #pragma unroll p_NnodesV{
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;

            if (e<Nelements) {
              const int element = elementList[e];

              const int gid = element*p_Nggeo;

              const dfloat Grr = ggeo[gid + p_G00ID];
              const dfloat Grs = ggeo[gid + p_G01ID];
              const dfloat Gss = ggeo[gid + p_G11ID];
              const dfloat J   = ggeo[gid + p_GWJID];

              dfloat res = Grr*r_qrr[et];
              dfloat res2 = Grs*r_qrs[et]; // A.
              dfloat res3 = Gss*r_qss[et];

              const int id = n + element*p_Np;
              Aq[id] = res+res2+res3;
            }
          }
        }
      }
    }
  }
}
//char4 version
@kernel void ellipticPartialAxTri2D_v4(const int Nelements,
    @restrict const  int   *  elementList,
    @restrict const  dfloat *  ggeo,
    @restrict const  dfloat *  SrrT,
    @restrict const  dfloat *  SrsT,
    @restrict const char4   *  IndT,
    @restrict const  dfloat *  SssT,
    @restrict const  dfloat *  MM,
    const dfloat lambda,
    @restrict const  dfloat  *  q,
    @restrict dfloat  *  Aq){

  // needs p_NnodesV (nodes per thread) and p_NblockV (elements per chunk) defined

  for(int eo=0;eo<Nelements;eo+=p_NnodesV*p_NblockV;@outer(0)){

    @shared dfloat s_q[p_NnodesV][p_NblockV][p_Np];

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;
            if(e<Nelements){
              //prefetch q
              const int element = elementList[e];
              const int id = n + element*p_Np;
              s_q[et][es][n] = q[id];
              //printf("maxNNz = %d \n", p_maxNnzPerRow);           
            }
          }
      }
    }

    @barrier("local");

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        // do this part irrespective of e
        dfloat r_qrr[p_NnodesV];
        dfloat r_qrs[p_NnodesV];
        dfloat r_qss[p_NnodesV];

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            r_qrr[et] = 0;
            r_qrs[et] = 0;
            r_qss[et] = 0;
          }
        //this loop is modified
        int shift = p_maxNnzPerRow/4;
        #pragma unroll p_maxNnzPerRow/4
          for (int k=0;k<shift;k++) {
            // prefetch operators to register for reuse

            char4 Indn = IndT[n*shift+k];
            int indicesn[4];
            indicesn[0] = (int) Indn.x;
            indicesn[1] = (int) Indn.y;
            indicesn[2] = (int) Indn.z;
            indicesn[3] = (int) Indn.w;
            //if (n== 2) {
            //  printf("k = %d max = %d put %d %d %d %d \n",k,p_maxNnzPerRow/4, (int) Indn.x, (int) Indn.y, (int) Indn.z, (int) Indn.w);
            // }
            //if IndList(i,j) ~=0 

            #pragma unroll 4            
              for (int k2 =0; k2<4; k2++){
                if (indicesn[k2] != 0){
                  /*if (es+eo ==0){

                    printf("n=%d k = %d  processing idx %d: Indices[%d] = %d need SrrT [%d*%d+%d]\n ",n,k, k2, k2, indicesn[k2], (indicesn[k2]-1),p_Np,n);
                    printf("accesing x[%d] \n", indicesn[k2]-1);                                    
                  }*/
                  //result(j) = result(j)+ Srr(j,IndList(i,j))*x(IndList(i,j));
                  const int id = indicesn[k2]-1;
                  //IndT[n*p_maxNnzPerRow+k]-1;
                  const dfloat Srr_nk = SrrT[id*p_Np+n];
                  const dfloat Srs_nk = SrsT[id*p_Np+n];
                  const dfloat Sss_nk = SssT[id*p_Np+n];
                  // (dphidr_n, dphidr_m)*(rx*rx+ry*ry)*q_m
                  // (dphidr_n, dphids_m)*(rx*sx+ry*sy)*q_m
                  // (dphids_n, dphidr_m)*(sx*rx+sy*ry)*q_m
                  // (dphids_n, dphids_m)*(sx*sx+sy*sy)*q_m

                  #pragma unroll p_NnodesV{
                    for(int et=0;et<p_NnodesV;++et){
                      // fetch from @shared (for reuse four times)
                      const dfloat r_qk = s_q[et][es][indicesn[k2]-1];
                      r_qrr[et] += Srr_nk*r_qk;
                      r_qrs[et] += Srs_nk*r_qk;
                      r_qss[et] += Sss_nk*r_qk;
                    }
                  }
                }
              }
          }
        // this part has to check for element index validity
        #pragma unroll p_NnodesV{
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;

            if (e<Nelements) {
              const int element = elementList[e];

              const int gid = element*p_Nggeo;

              const dfloat Grr = ggeo[gid + p_G00ID];
              const dfloat Grs = ggeo[gid + p_G01ID];
              const dfloat Gss = ggeo[gid + p_G11ID];
              const dfloat J   = ggeo[gid + p_GWJID];

              dfloat res = Grr*r_qrr[et];
              dfloat res2 = Grs*r_qrs[et]; // A.
              dfloat res3 = Gss*r_qss[et];

              const int id = n + element*p_Np;
              Aq[id] = res+res2+res3;
            }
          }
        }
      }
    }
  }
}

//char4 storage BUT the matrices Srs, Srr, Sss are accessed ROW-WISE
@kernel void ellipticPartialAxTri2D_v5(const int Nelements,
    @restrict const  int   *  elementList,
    @restrict const  dfloat *  ggeo,
    @restrict const  dfloat *  Srr,
    @restrict const  dfloat *  Srs,
    @restrict const char4   *  IndT,
    @restrict const  dfloat *  Sss,
    @restrict const  dfloat *  MM,
    const dfloat lambda,
    @restrict const  dfloat  *  q,
    @restrict dfloat  *  Aq){

  // needs p_NnodesV (nodes per thread) and p_NblockV (elements per chunk) defined

  for(int eo=0;eo<Nelements;eo+=p_NnodesV*p_NblockV;@outer(0)){

    @shared dfloat s_q[p_NnodesV][p_NblockV][p_Np];

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;
            if(e<Nelements){
              //prefetch q
              const int element = elementList[e];
              const int id = n + element*p_Np;
              s_q[et][es][n] = q[id];
              //printf("maxNNz = %d \n", p_maxNnzPerRow);           
            }
          }
      }
    }

    @barrier("local");

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        // do this part irrespective of e
        dfloat r_qrr[p_NnodesV];
        dfloat r_qrs[p_NnodesV];
        dfloat r_qss[p_NnodesV];

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            r_qrr[et] = 0;
            r_qrs[et] = 0;
            r_qss[et] = 0;
          }
        //this loop is modified
        int shift = p_maxNnzPerRow/4;
        #pragma unroll p_maxNnzPerRow/4
          for (int k=0;k<shift;k++) {
            // prefetch operators to register for reuse

            char4 Indn = IndT[n*shift+k];
            int indicesn[4];
            indicesn[0] = (int) Indn.x;
            indicesn[1] = (int) Indn.y;
            indicesn[2] = (int) Indn.z;
            indicesn[3] = (int) Indn.w;
            //if (n== 2) {
            //  printf("k = %d max = %d put %d %d %d %d \n",k,p_maxNnzPerRow/4, (int) Indn.x, (int) Indn.y, (int) Indn.z, (int) Indn.w);
            // }

            #pragma unroll 4            
              for (int k2 =0; k2<4; k2++){
                if (indicesn[k2] != 0){
                /* if (es+eo ==0){

                    printf("n=%d k = %d  processing idx %d: Indices[%d] = %d need SrrT [%d]\n ",n,k, k2, k2, indicesn[k2], (indicesn[k2]-1)*p_Np+n);
                    printf("accesing x[%d] \n", indicesn[k2]-1);                                    
                  }*/
                  const int id = indicesn[k2]-1;
                  
                  const dfloat Srr_nk = Srr[n*p_Np+id];
                  const dfloat Srs_nk = Srs[n*p_Np+id];
                  const dfloat Sss_nk = Sss[n*p_Np+id];
                  
                  // (dphidr_n, dphidr_m)*(rx*rx+ry*ry)*q_m
                  // (dphidr_n, dphids_m)*(rx*sx+ry*sy)*q_m
                  // (dphids_n, dphidr_m)*(sx*rx+sy*ry)*q_m
                  // (dphids_n, dphids_m)*(sx*sx+sy*sy)*q_m

                  #pragma unroll p_NnodesV{
                    for(int et=0;et<p_NnodesV;++et){
                      // fetch from @shared (for reuse four times)
                      const dfloat r_qk = s_q[et][es][indicesn[k2]-1];
                      r_qrr[et] += Srr_nk*r_qk;
                      r_qrs[et] += Srs_nk*r_qk;
                      r_qss[et] += Sss_nk*r_qk;
                    }
                  }
                }
              }
          }
        // this part has to check for element index validity
        #pragma unroll p_NnodesV{
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;

            if (e<Nelements) {
              const int element = elementList[e];

              const int gid = element*p_Nggeo;

              const dfloat Grr = ggeo[gid + p_G00ID];
              const dfloat Grs = ggeo[gid + p_G01ID];
              const dfloat Gss = ggeo[gid + p_G11ID];
              const dfloat J   = ggeo[gid + p_GWJID];

              dfloat res = Grr*r_qrr[et];
              dfloat res2 = Grs*r_qrs[et]; // A.
              dfloat res3 = Gss*r_qss[et];

              const int id = n + element*p_Np;
              Aq[id] = res+res2+res3;
            }
          }
        }
      }
    }
  }
}


//char4 storage BUT the COMPRESSED rectangular matrices Srs, Srr, Sss are accessed COLUMN-WISE
@kernel void ellipticPartialAxTri2D_v6(const int Nelements,
				      @restrict const  int   *  elementList,
				      @restrict const  dfloat *  ggeo,
				      @restrict const  dfloat *  Srr,
				      @restrict const  dfloat *  Srs,
				      @restrict const char4   *  IndT,
				      @restrict const  dfloat *  Sss,
				      @restrict const  dfloat *  MM,
				      const dfloat lambda,
				      @restrict const  dfloat  *  q,
				      @restrict dfloat  *  Aq){
  
  // needs p_NnodesV (nodes per thread) and p_NblockV (elements per chunk) defined
  
  for(int eo=0;eo<Nelements;eo+=p_NnodesV*p_NblockV;@outer(0)){

    @shared dfloat s_q[p_NnodesV][p_NblockV][p_Np];

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;
            if(e<Nelements){
              //prefetch q
              const int element = elementList[e];
              const int id = n + element*p_Np;
              s_q[et][es][n] = q[id];
            }
          }
      }
    }

    @barrier("local");

    for(int es=0;es<p_NblockV;++es;@inner(1)){
      for(int n=0;n<p_Np;++n;@inner(0)){

        // do this part irrespective of e
        dfloat r_qrr[p_NnodesV];
        dfloat r_qrs[p_NnodesV];
        dfloat r_qss[p_NnodesV];

        #pragma unroll p_NnodesV
          for(int et=0;et<p_NnodesV;++et){
            r_qrr[et] = 0;
            r_qrs[et] = 0;
            r_qss[et] = 0;
          }

        int shift = p_maxNnzPerRow/4; // TW: need to make sure this is multiple of 4
        #pragma unroll p_maxNnzPerRow/4
          for (int k=0;k<shift;k++) {
            // prefetch operators to register for reuse

            char4 Indn = IndT[n*shift+k];
            int indicesn[4];
            indicesn[0] = (int) Indn.x;
            indicesn[1] = (int) Indn.y;
            indicesn[2] = (int) Indn.z;
            indicesn[3] = (int) Indn.w;

            #pragma unroll 4            
              for (int k2 =0; k2<4; k2++){
                if (indicesn[k2] != 0){
		  // assume Srr, Srs, Sss are stored as a row-major matrix with maxNnzPerRow rows and Np columns
                  const int id = n + (k2+4*k)*p_Np;
                  const dfloat Srr_nk = Srr[id];
                  const dfloat Srs_nk = Srs[id];
                  const dfloat Sss_nk = Sss[id];
                  
                  // (dphidr_n, dphidr_m)*(rx*rx+ry*ry)*q_m
                  // (dphidr_n, dphids_m)*(rx*sx+ry*sy)*q_m
                  // (dphids_n, dphidr_m)*(sx*rx+sy*ry)*q_m
                  // (dphids_n, dphids_m)*(sx*sx+sy*sy)*q_m

                  #pragma unroll p_NnodesV{
                    for(int et=0;et<p_NnodesV;++et){
                      // fetch from @shared (for reuse three times)
		      // 6 flops per 8 bytes
                      const dfloat r_qk = s_q[et][es][indicesn[k2]-1];
                      r_qrr[et] += Srr_nk*r_qk;
                      r_qrs[et] += Srs_nk*r_qk;
                      r_qss[et] += Sss_nk*r_qk;
                    }
                  }
                }
              }
          }

        // this part has to check for element index validity
        #pragma unroll p_NnodesV{
          for(int et=0;et<p_NnodesV;++et){
            const int e = eo + es + et*p_NblockV;
	    
            if (e<Nelements) {
              const int element = elementList[e];
	      
              const int gid = element*p_Nggeo;

              const dfloat Grr = ggeo[gid + p_G00ID];
              const dfloat Grs = ggeo[gid + p_G01ID];
              const dfloat Gss = ggeo[gid + p_G11ID];
              const dfloat J   = ggeo[gid + p_GWJID];

              dfloat res = Grr*r_qrr[et];
              dfloat res2 = Grs*r_qrs[et]; // A.
              dfloat res3 = Gss*r_qss[et];

              const int id = n + element*p_Np;
              Aq[id] = res+res2+res3;
            }
          }
        }
      }
    }
  }
}

